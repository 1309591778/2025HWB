# 23_task3_lightgbm_transfer.py
import os
import numpy as np
import pandas as pd
import joblib
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

def create_output_dir():
    output_dir = os.path.join('..', 'data', 'processed', 'task3_outputs_lightgbm')
    os.makedirs(output_dir, exist_ok=True)
    return output_dir

def main():
    print("ğŸš€ ä»»åŠ¡ä¸‰ï¼šåŸºäº LightGBM çš„è¿ç§»è¯Šæ–­ï¼ˆæ—  DANNï¼‰å¼€å§‹æ‰§è¡Œ...")
    output_dir = create_output_dir()

    # --- é˜¶æ®µä¸€ï¼šåŠ è½½é¢„å¤„ç†å™¨å’Œæ¨¡å‹ ---
    print("\n--- é˜¶æ®µä¸€ï¼šåŠ è½½é¢„å¤„ç†å™¨å’Œæ¨¡å‹ ---")
    PROCESSED_DIR = os.path.join('..', 'data', 'processed')
    TASK2_OUTPUTS_DIR = os.path.join(PROCESSED_DIR, 'task2_outputs_final')

    # åŠ è½½é¢„å¤„ç†å™¨
    SCALER_PATH = os.path.join(TASK2_OUTPUTS_DIR, 'final_scaler.joblib')
    LE_PATH = os.path.join(TASK2_OUTPUTS_DIR, 'final_label_encoder.joblib')
    MODEL_PATH = os.path.join(TASK2_OUTPUTS_DIR, 'final_lgb_model.txt')

    try:
        scaler = joblib.load(SCALER_PATH)
        le = joblib.load(LE_PATH)
        lgb_model = lgb.Booster(model_file=MODEL_PATH)
        print("âœ… æˆåŠŸåŠ è½½ StandardScalerã€LabelEncoder å’Œ LightGBM æ¨¡å‹ã€‚")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        exit(1)

    # --- é˜¶æ®µäºŒï¼šåŠ è½½ç›®æ ‡åŸŸç‰¹å¾ ---
    print("\n--- é˜¶æ®µäºŒï¼šåŠ è½½ç›®æ ‡åŸŸç‰¹å¾ ---")
    TARGET_FEATURES_PATH = os.path.join(PROCESSED_DIR, 'target_features.csv')
    try:
        df_target = pd.read_csv(TARGET_FEATURES_PATH)
        print(f"âœ… æˆåŠŸåŠ è½½ç›®æ ‡åŸŸç‰¹å¾: {df_target.shape}")
    except Exception as e:
        print(f"âŒ æ— æ³•åŠ è½½ç›®æ ‡åŸŸç‰¹å¾: {e}")
        exit(1)

    # æå–ç‰¹å¾åˆ—ï¼ˆæ’é™¤ 'source_file', 'rpm'ï¼‰
    feature_cols = [col for col in df_target.columns if col not in ['source_file', 'rpm']]
    X_target = df_target[feature_cols].values
    filenames = df_target['source_file'].values

    # æ ‡å‡†åŒ–
    X_target_scaled = scaler.transform(X_target)

    # --- é˜¶æ®µä¸‰ï¼šé¢„æµ‹ ---
    print("\n--- é˜¶æ®µä¸‰ï¼šæ‰§è¡Œé¢„æµ‹ ---")
    y_pred_proba = lgb_model.predict(X_target_scaled)
    y_pred_int = np.argmax(y_pred_proba, axis=1)
    y_pred_labels = le.inverse_transform(y_pred_int)
    confidence = np.max(y_pred_proba, axis=1)

    print("ğŸ“Š é¢„æµ‹ç±»åˆ«åˆ†å¸ƒï¼ˆæ ·æœ¬çº§ï¼‰:")
    unique, counts = np.unique(y_pred_labels, return_counts=True)
    for u, c in zip(unique, counts):
        print(f"  {u}: {c} ä¸ªæ ·æœ¬")

    # --- é˜¶æ®µå››ï¼šæŒ‰æ–‡ä»¶åæŠ•ç¥¨ ---
    print("\n--- é˜¶æ®µå››ï¼šæŒ‰æ–‡ä»¶åè¿›è¡ŒæŠ•ç¥¨ ---")
    file_predictions = {}
    for filename in np.unique(filenames):
        mask = (filenames == filename)
        file_labels = y_pred_labels[mask]
        file_conf = confidence[mask]

        # æŠ•ç¥¨ï¼šå¾—ç¥¨æœ€å¤šçš„ç±»åˆ«
        votes = pd.Series(file_labels).value_counts()
        predicted_class = votes.index[0]
        vote_ratio = votes.iloc[0] / len(file_labels)
        avg_confidence = np.mean(file_conf)
        final_confidence = vote_ratio * avg_confidence  # ç»¼åˆç½®ä¿¡åº¦

        file_predictions[filename] = {
            'predicted_label': predicted_class,
            'confidence': final_confidence,
            'total_samples': len(file_labels),
            'vote_distribution': votes.to_dict()
        }
        print(f"  - {filename}: {predicted_class} (ç½®ä¿¡åº¦: {final_confidence:.4f})")

    # --- é˜¶æ®µäº”ï¼šä¿å­˜ç»“æœ ---
    print("\n--- é˜¶æ®µäº”ï¼šä¿å­˜é¢„æµ‹ç»“æœ ---")
    result_df = pd.DataFrame([
        {
            'filename': fname,
            'predicted_label': info['predicted_label'],
            'confidence': info['confidence'],
            'total_samples': info['total_samples']
        }
        for fname, info in file_predictions.items()
    ]).sort_values('filename').reset_index(drop=True)

    RESULTS_CSV = os.path.join(output_dir, '23_target_predictions_lightgbm.csv')
    result_df.to_csv(RESULTS_CSV, index=False)
    print(f"âœ… æ–‡ä»¶çº§é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: {RESULTS_CSV}")

    # --- é˜¶æ®µå…­ï¼šå¯è§†åŒ– ---
    print("\n--- é˜¶æ®µå…­ï¼šå¯è§†åŒ–ç»“æœ ---")

    # 1. é¢„æµ‹ç±»åˆ«åˆ†å¸ƒé¥¼å›¾
    plt.figure(figsize=(8, 6))
    labels = result_df['predicted_label']
    unique_labels, counts = np.unique(labels, return_counts=True)
    colors = sns.color_palette("husl", len(unique_labels))
    plt.pie(counts, labels=unique_labels, autopct='%1.1f%%', startangle=140, colors=colors)
    plt.title('ç›®æ ‡åŸŸæ–‡ä»¶é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ (LightGBM)', fontsize=14, weight='bold')
    plt.axis('equal')
    pie_path = os.path.join(output_dir, '23_prediction_distribution_pie.png')
    plt.savefig(pie_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… é¢„æµ‹åˆ†å¸ƒé¥¼å›¾å·²ä¿å­˜è‡³: {pie_path}")

    # 2. ç½®ä¿¡åº¦ç›´æ–¹å›¾
    plt.figure(figsize=(10, 6))
    confidences = result_df['confidence']
    plt.hist(confidences, bins=15, edgecolor='black', alpha=0.7, color='skyblue')
    plt.xlabel('æ–‡ä»¶é¢„æµ‹ç½®ä¿¡åº¦', fontsize=12)
    plt.ylabel('æ–‡ä»¶æ•°é‡', fontsize=12)
    plt.title('ç›®æ ‡åŸŸæ–‡ä»¶é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ (LightGBM)', fontsize=14, weight='bold')
    plt.grid(True, alpha=0.3)
    mean_conf = np.mean(confidences)
    median_conf = np.median(confidences)
    stats_text = f'å‡å€¼: {mean_conf:.3f}\nä¸­ä½æ•°: {median_conf:.3f}'
    plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes, fontsize=10,
             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    hist_path = os.path.join(output_dir, '23_prediction_confidence_hist.png')
    plt.savefig(hist_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ç½®ä¿¡åº¦ç›´æ–¹å›¾å·²ä¿å­˜è‡³: {hist_path}")

    print(f"\nğŸ† ä»»åŠ¡ä¸‰è¿ç§»è¯Šæ–­å®Œæˆï¼")
    print(f"   - æ¨¡å‹: LightGBM (æ—  DANN)")
    print(f"   - é¢„æµ‹æ–¹å¼: æ ·æœ¬çº§é¢„æµ‹ â†’ æ–‡ä»¶çº§æŠ•ç¥¨")
    print(f"   - ç»“æœä¿å­˜è·¯å¾„: {os.path.abspath(output_dir)}")

if __name__ == "__main__":
    main()