import os
import re
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib import font_manager
from matplotlib.ticker import PercentFormatter
from sklearn.feature_selection import f_classif
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
# === æ–°å¢å¯¼å…¥ ===
from sklearn.utils import resample
from collections import Counter


# === æ–°å¢ç»“æŸ ===


# ==============================================================================
# 0. å­—ä½“è®¾ç½®å‡½æ•°
# ==============================================================================
def set_chinese_font():
    """
    å¼ºåˆ¶è®¾ç½®ä¸­æ–‡å­—ä½“ä¸º 'Microsoft YaHei'ï¼Œè§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ã€‚
    """
    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']
    plt.rcParams['axes.unicode_minus'] = False
    print("âœ… å·²è®¾ç½®ä¸­æ–‡å­—ä½“ã€‚")


# ==============================================================================
# 1. ä¸»ç¨‹åº
# ==============================================================================
if __name__ == "__main__":
    set_chinese_font()

    # --- è·¯å¾„å®šä¹‰ ---
    PROCESSED_DIR = os.path.join('..', 'data', 'processed')
    FEATURES_PATH = os.path.join(PROCESSED_DIR, 'source_features.csv')
    OUTPUT_DIR = os.path.join(PROCESSED_DIR, 'task1_outputs')
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # --- æ•°æ®åŠ è½½ ---
    try:
        df_features = pd.read_csv(FEATURES_PATH)
    except FileNotFoundError:
        print(f"â€¼ï¸ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç‰¹å¾æ–‡ä»¶ {FEATURES_PATH}ã€‚è¯·å…ˆè¿è¡Œ03è„šæœ¬ç”Ÿæˆå¢å¼ºç‰ˆç‰¹å¾é›†ã€‚")
        exit()

    if 'filename' not in df_features.columns:
        print("â€¼ï¸ é”™è¯¯ï¼šç‰¹å¾æ–‡ä»¶ä¸­ç¼ºå°‘'filename'åˆ—ã€‚è¯·æŒ‰æŒ‡å¯¼ä¿®æ”¹å¹¶é‡æ–°è¿è¡Œ02å’Œ03è„šæœ¬ã€‚")
        exit()

    # === æ–°å¢ï¼šå¤„ç†ç±»åˆ«ä¸å¹³è¡¡ (Nç±»æ ·æœ¬å¢å¼º) ===
    print(f"\nğŸ“Š åŸå§‹ç±»åˆ«åˆ†å¸ƒ: {dict(Counter(df_features['label']))}")

    # åˆ†ç¦»å„ç±»åˆ«æ•°æ®
    df_N = df_features[df_features['label'] == 'N']
    df_B = df_features[df_features['label'] == 'B']
    df_IR = df_features[df_features['label'] == 'IR']
    df_OR = df_features[df_features['label'] == 'OR']

    print(f"  - Nç±»æ ·æœ¬æ•°: {len(df_N)}")
    print(f"  - Bç±»æ ·æœ¬æ•°: {len(df_B)}")
    print(f"  - IRç±»æ ·æœ¬æ•°: {len(df_IR)}")
    print(f"  - ORç±»æ ·æœ¬æ•°: {len(df_OR)}")

    # å¯¹Nç±»è¿›è¡Œè¿‡é‡‡æ ·ï¼ˆä¸Šé‡‡æ ·åˆ°ä¸æœ€å¤§ç±»åˆ«ç›¸è¿‘ï¼‰
    # ç›®æ ‡ï¼šå°†Nç±»ä»~800ä¸ªå¢åŠ åˆ°~4000ä¸ªï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
    target_N_samples = 4000
    if len(df_N) < target_N_samples:
        df_N_upsampled = resample(df_N,
                                  replace=True,  # æœ‰æ”¾å›æŠ½æ ·
                                  n_samples=target_N_samples,
                                  random_state=42)
        print(f"  - Nç±»ä¸Šé‡‡æ ·å: {len(df_N_upsampled)}")

        # ç»„åˆåŸå§‹æ•°æ®å’Œä¸Šé‡‡æ ·æ•°æ®
        df_features_balanced = pd.concat([df_N_upsampled, df_B, df_IR, df_OR])
        print(f"  - å¹³è¡¡åæ€»æ ·æœ¬æ•°: {len(df_features_balanced)}")
        print(f"  - å¹³è¡¡åç±»åˆ«åˆ†å¸ƒ: {dict(Counter(df_features_balanced['label']))}")

        # ä½¿ç”¨å¹³è¡¡åçš„æ•°æ®é›†
        df_features = df_features_balanced
    else:
        print("  - Nç±»æ ·æœ¬æ•°å·²è¶³å¤Ÿï¼Œæ— éœ€ä¸Šé‡‡æ ·")
    # === æ–°å¢ç»“æŸ ===

    # === æ–°å¢ï¼šä¸“ä¸šç¼ºå¤±å€¼å¤„ç† ===
    print(f"\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥...")
    nan_count = df_features.isnull().sum().sum()
    inf_count = np.isinf(df_features.select_dtypes(include=[np.number])).sum().sum()
    print(f"  - NaNå€¼ç»Ÿè®¡: {nan_count} ä¸ª")
    print(f"  - æ— ç©·å€¼ç»Ÿè®¡: {inf_count} ä¸ª")

    # å¤„ç†ä»»ä½•å¯èƒ½çš„å¼‚å¸¸å€¼
    if nan_count > 0 or inf_count > 0:
        print("  - å‘ç°å¼‚å¸¸å€¼ï¼Œæ­£åœ¨è¿›è¡Œä¸“ä¸šå¤„ç†...")

        # å°†æ— ç©·å€¼æ›¿æ¢ä¸ºNaN
        df_features = df_features.replace([np.inf, -np.inf], np.nan)

        # ä½¿ç”¨å‡å€¼å¡«å……NaNå€¼
        numeric_columns = df_features.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            if df_features[col].isnull().any():
                mean_value = df_features[col].mean()
                df_features[col].fillna(mean_value, inplace=True)

        print("  - å¼‚å¸¸å€¼å¤„ç†å®Œæˆ")
    # === æ–°å¢ç»“æŸ ===

    X = df_features.drop(columns=['label', 'rpm', 'filename'])
    y_str = df_features['label']
    le = LabelEncoder()
    y = le.fit_transform(y_str)

    # --- åéªŒéªŒè¯ 1: ç›¸å…³æ€§åˆ†æ ---
    print("\nğŸš€ åéªŒéªŒè¯ 1: åˆ†æé«˜åº¦ç›¸å…³çš„ç‰¹å¾å¯¹...")
    corr_matrix = X.corr().abs()
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    highly_correlated = [column for column in upper.columns if any(upper[column] > 0.8)]
    for col in highly_correlated:
        correlated_with = upper.index[upper[col] > 0.8].tolist()
        print(f"  - ç‰¹å¾ '{col}' ä¸ {correlated_with} é«˜åº¦ç›¸å…³ (r>0.8)")

    # --- åéªŒéªŒè¯ 2: æ–¹å·®åˆ†æ (ANOVA) ---
    print("\nğŸš€ åéªŒéªŒè¯ 2: ANOVA Få€¼æ’åº (éªŒè¯ç‰¹å¾åŒºåˆ†åº¦)...")
    f_values, p_values = f_classif(X, y)
    df_anova = pd.DataFrame({'feature': X.columns, 'F_score': f_values}).sort_values(by='F_score', ascending=False)
    print("  - ANOVA Få€¼æ’åå‰15çš„ç‰¹å¾:")
    print(df_anova.head(15))

    # --- åéªŒéªŒè¯ 3: éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§ ---
    print("\nğŸš€ åéªŒéªŒè¯ 3: éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§æ’åº...")
    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
    model.fit(X, y)
    importances = model.feature_importances_
    df_importance = pd.DataFrame({'feature': X.columns, 'importance': importances}).sort_values(by='importance',
                                                                                                ascending=False)
    print("  - éšæœºæ£®æ—æ¨¡å‹è®¤ä¸ºæœ€é‡è¦çš„15ä¸ªç‰¹å¾:")
    print(df_importance.head(15))

    # å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
    plt.figure(figsize=(12, 10))
    sns.barplot(x='importance', y='feature', data=df_importance.head(20))
    plt.title('Top 20 ç‰¹å¾é‡è¦æ€§æ’åº (éšæœºæ£®æ—)', fontsize=16)
    save_path_bar = os.path.join(OUTPUT_DIR, 'task1_feature_importance_bar.png')
    plt.savefig(save_path_bar, dpi=300)
    print(f"\nâœ… ç‰¹å¾é‡è¦æ€§æ’åºå›¾å·²ä¿å­˜è‡³: {os.path.abspath(save_path_bar)}")
    plt.close()

    # --- ã€æ–°å¢ã€‘å¯è§†åŒ–ï¼šç‰¹å¾ç´¯ç§¯é‡è¦æ€§æ›²çº¿ ---
    print("\nğŸš€ æ–°å¢å¯è§†åŒ–ï¼šç”Ÿæˆç‰¹å¾ç´¯ç§¯é‡è¦æ€§æ›²çº¿...")

    # è®¡ç®—ç´¯ç§¯é‡è¦æ€§åˆ†æ•° (å·²ç»æ˜¯æŒ‰é‡è¦æ€§é™åºæ’åˆ—çš„)
    cumulative_importance = np.cumsum(df_importance['importance'])

    # åˆ›å»ºå›¾è¡¨
    plt.figure(figsize=(12, 8))
    plt.plot(range(1, len(cumulative_importance) + 1), cumulative_importance, marker='o', linestyle='--')

    # è®¾ç½®Yè½´ä¸ºç™¾åˆ†æ¯”æ ¼å¼
    plt.gca().yaxis.set_major_formatter(PercentFormatter(1.0))

    # æ ‡è®°95%å’Œ99%çš„é‡è¦æ€§é˜ˆå€¼çº¿
    plt.axhline(y=0.95, color='r', linestyle='--', label='95% ç´¯ç§¯é‡è¦æ€§')

    # æ‰¾åˆ°è¾¾åˆ°95%é˜ˆå€¼éœ€è¦å¤šå°‘ä¸ªç‰¹å¾
    try:
        num_features_95 = np.where(cumulative_importance >= 0.95)[0][0] + 1
        plt.text(num_features_95 + 0.5, 0.93, f'Top {num_features_95} ä¸ªç‰¹å¾', color='r', fontsize=12)
        # ç»˜åˆ¶å‚çº¿ä»¥æ›´æ¸…æ™°åœ°æŒ‡ç¤ºä½ç½®
        plt.axvline(x=num_features_95, color='r', linestyle=':', alpha=0.7)
    except IndexError:
        print("  - æ³¨æ„ï¼šæ‰€æœ‰ç‰¹å¾çš„ç´¯ç§¯é‡è¦æ€§æœªè¾¾åˆ°95%ã€‚")
        # å¦‚æœæ²¡æœ‰è¾¾åˆ°95%ï¼Œä½¿ç”¨å‰50%çš„ç‰¹å¾
        num_features_95 = max(1, len(df_importance) // 2)

    plt.title('ç‰¹å¾ç´¯ç§¯é‡è¦æ€§æ›²çº¿', fontsize=18, weight='bold')
    plt.xlabel('æŒ‰é‡è¦æ€§æ’åºçš„ç‰¹å¾æ•°é‡', fontsize=14)
    plt.ylabel('ç´¯ç§¯é‡è¦æ€§', fontsize=14)
    plt.grid(True)
    plt.legend()
    plt.tight_layout()

    save_path_curve = os.path.join(OUTPUT_DIR, 'task1_cumulative_feature_importance_curve.png')
    plt.savefig(save_path_curve, dpi=300)
    print(f"âœ… ç‰¹å¾ç´¯ç§¯é‡è¦æ€§æ›²çº¿å›¾å·²ä¿å­˜è‡³: {os.path.abspath(save_path_curve)}")
    plt.close()

    # --- æœ€ç»ˆç­›é€‰å†³ç­– ---
    print("\nğŸš€ æœ€ç»ˆå†³ç­–ï¼šç­›é€‰ç‰¹å¾...")
    # æˆ‘ä»¬å¯ä»¥æ ¹æ®ç´¯ç§¯é‡è¦æ€§æ›²çº¿çš„ç»“æœæ¥åŠ¨æ€å†³å®šä¿ç•™å¤šå°‘ä¸ªç‰¹å¾
    # ä¾‹å¦‚ï¼Œä¿ç•™è¾¾åˆ°95%é‡è¦æ€§çš„æ‰€æœ‰ç‰¹å¾
    final_features_to_keep = df_importance['feature'].iloc[:num_features_95].tolist()

    # æ£€æŸ¥å¹¶ç§»é™¤é«˜åº¦ç›¸å…³çš„ç‰¹å¾
    # (è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å»å†—ä½™é€»è¾‘ç¤ºä¾‹)
    for col in highly_correlated:
        if col in final_features_to_keep:
            correlated_with = upper.index[upper[col] > 0.8].tolist()
            # å¦‚æœä¸colç›¸å…³çš„ç‰¹å¾ä¹Ÿåœ¨ä¿ç•™åˆ—è¡¨ä¸­ï¼Œä¸”colçš„é‡è¦æ€§æ›´ä½ï¼Œåˆ™è€ƒè™‘ç§»é™¤col
            # æ­¤å¤„é€»è¾‘è¾ƒä¸ºå¤æ‚ï¼Œå¯ä»¥å…ˆæ‰‹åŠ¨å†³ç­–ï¼Œä¾‹å¦‚æˆ‘ä»¬å·²çŸ¥rmså’Œstd_devé«˜åº¦ç›¸å…³
            if 'std_dev' in final_features_to_keep and 'rms' in final_features_to_keep:
                # å‡è®¾æˆ‘ä»¬é€šè¿‡ANOVAæˆ–æ¨¡å‹é‡è¦æ€§ï¼Œå†³å®šä¿ç•™std_dev
                final_features_to_keep.remove('rms')

    print(f"  - âœ… å†³ç­–å®Œæˆï¼šç­›é€‰å‡º {len(final_features_to_keep)} ä¸ªç‰¹å¾ç”¨äºåç»­å»ºæ¨¡ã€‚")
    # print(f"  - ç­›é€‰å‡ºçš„ç‰¹å¾åˆ—è¡¨: {final_features_to_keep}")

    # --- ã€ä¿®æ”¹ã€‘ä¿å­˜æœ€ç»ˆç­›é€‰çš„ç‰¹å¾é›†ï¼Œä¿è¯ç‰¹å¾åˆ—é¡ºåº ---
    # 1. ç¡®å®šæœ€ç»ˆåˆ—é¡ºåºï¼š['filename', 'label', 'rpm'] + ç­›é€‰å‡ºçš„ç‰¹å¾ï¼ˆæŒ‰é‡è¦æ€§æ’åºé¡ºåºï¼‰
    final_columns = ['filename', 'label', 'rpm'] + final_features_to_keep # ä¿æŒé‡è¦æ€§æ’åºé¡ºåº
    # 2. ä» df_features ä¸­é€‰æ‹©è¿™äº›åˆ—ï¼Œå¹¶æŒ‰æŒ‡å®šé¡ºåºæ’åˆ—
    df_final_source = df_features[final_columns]

    save_path_source = os.path.join(PROCESSED_DIR, 'source_features_selected.csv')
    df_final_source.to_csv(save_path_source, index=False)
    print(f"  - âœ… ç­›é€‰åçš„æºåŸŸç‰¹å¾é›†å·²ä¿å­˜è‡³: {os.path.abspath(save_path_source)}")

    # --- ã€ä¿®æ”¹ã€‘ä¿å­˜ç­›é€‰å‡ºçš„ç‰¹å¾åç§°åˆ—è¡¨ï¼Œé¡ºåºä¸æºåŸŸç‰¹å¾é›†ä¸€è‡´ ---
    # ä¿å­˜çš„ç‰¹å¾åç§°é¡ºåºåº”ä¸ df_final_source ä¸­çš„ç‰¹å¾åˆ—é¡ºåºä¸€è‡´
    # å³ï¼Œä¸ final_features_to_keep çš„é¡ºåºä¸€è‡´
    save_path_feature_list = os.path.join(PROCESSED_DIR, 'selected_feature_names.txt')
    with open(save_path_feature_list, 'w') as f:
        for feature_name in final_features_to_keep: # ä½¿ç”¨ä¸ df_final_source ç›¸åŒçš„é¡ºåº
            f.write(f"{feature_name}\n")
    print(f"  - âœ… ç­›é€‰å‡ºçš„ç‰¹å¾åç§°åˆ—è¡¨å·²ä¿å­˜è‡³: {os.path.abspath(save_path_feature_list)}")

    print("\nğŸ‰ ä»»åŠ¡ä¸€çš„ç‰¹å¾ç­›é€‰å·¥ä½œå·²å®Œæˆï¼")