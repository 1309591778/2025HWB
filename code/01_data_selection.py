import os
import re
import pandas as pd
import numpy as np
#æ•°æ®åˆ†æä¸ç­›é€‰

# ==============================================================================
# 1. é€’å½’æ‰«æä¸å…ƒæ•°æ®æ„å»º (å†æ¬¡ä¿®æ­£æ­£åˆ™è¡¨è¾¾å¼)
# ==============================================================================
def build_metadata_from_walk(source_root_dir: str):
    """
    ã€æœ€ç»ˆä¿®æ­£ç‰ˆã€‘æ›´æ–°æ­£åˆ™è¡¨è¾¾å¼ï¼Œä½¿å…¶èƒ½å¤Ÿå…¼å®¹æ‰€æœ‰å·²çŸ¥çš„æ–‡ä»¶å‘½åæ ¼å¼ã€‚
    """
    records = []
    total_files_found = 0
    unparsed_files = []

    print(f"ğŸ” å¼€å§‹é€’å½’æ‰«ææ ¹ç›®å½•: {os.path.abspath(source_root_dir)}")

    if not os.path.exists(source_root_dir):
        print(f"â€¼ï¸ é”™è¯¯ï¼šæŒ‡å®šçš„è·¯å¾„ä¸å­˜åœ¨ï¼è¯·æ£€æŸ¥è·¯å¾„: {os.path.abspath(source_root_dir)}")
        return pd.DataFrame()

    for root, dirs, files in os.walk(source_root_dir):
        mat_files_in_this_folder = [f for f in files if f.endswith('.mat')]
        total_files_found += len(mat_files_in_this_folder)

        for filename in mat_files_in_this_folder:
            file_path = os.path.join(root, filename)
            path_lower = file_path.lower().replace('\\', '/')

            sampling_rate = '48k' if '48khz' in path_lower else '12k'
            sensor = 'DE' if 'de_data' in path_lower or 'normal_data' in path_lower else \
                'FE' if 'fe_data' in path_lower else \
                    'BA' if 'ba_data' in path_lower else 'unknown'

            fault_type, fault_size, load = None, None, None
            if 'normal_data' in path_lower:
                fault_type, fault_size, load = 'N', '000', '0'
            else:
                # ==================== æœ€ç»ˆæ ¸å¿ƒä¿®æ”¹åœ¨æ­¤è¡Œ ====================
                # æ–°çš„æ­£åˆ™è¡¨è¾¾å¼å¯ä»¥å¤„ç† OR007@6_0.mat, B007_0.mat, B028_0_(1797rpm).mat ç­‰æ‰€æœ‰æ ¼å¼
                match = re.match(r'([A-Z]+)(\d{3})(?:@\d+)?_(\d).*?\.mat', filename, re.IGNORECASE)
                # ===========================================================

                if match:
                    # æ³¨æ„ï¼šå› ä¸ºå¢åŠ äº†ä¸€ä¸ªéæ•è·ç»„ (?:@\d+)?, åˆ†ç»„ç´¢å¼•ä¸å˜
                    ft, fs, ld = match.groups()
                    fault_type, fault_size, load = ft.upper(), fs, ld

            if fault_type:
                records.append({
                    'filename': filename, 'file_path': file_path,
                    'sampling_rate': sampling_rate, 'sensor': sensor,
                    'fault_type': fault_type, 'fault_size': fault_size, 'load': load
                })
            else:
                unparsed_files.append(file_path)

    print(f"âœ… æ‰«æå®Œæˆï¼Œæ€»å…±æ‰¾åˆ° {total_files_found} ä¸ª .mat æ–‡ä»¶ã€‚")
    if unparsed_files:
        print(f"âš ï¸  å…¶ä¸­æœ‰ {len(unparsed_files)} ä¸ªæ–‡ä»¶å› å‘½åä¸è§„èŒƒæ— æ³•è§£æï¼Œåˆ—è¡¨å¦‚ä¸‹:")
        for f in unparsed_files:
            print(f"  - {f}")

    return pd.DataFrame(records)


# ==============================================================================
# 2. ä¿è¯æ•°é‡çš„æ•°æ®ç­›é€‰ç­–ç•¥ (ä¿æŒä¸å˜)
# ==============================================================================
def select_files_guaranteed_count(df: pd.DataFrame):
    """
    ã€æ— éœ€ä¿®æ”¹ã€‘æ ¹æ®â€œå¤šæ ·æ€§ä¼˜å…ˆï¼Œæ•°é‡ä¿è¯â€åŸåˆ™ç­›é€‰æ–‡ä»¶ã€‚
    """
    print("\nğŸš€ å¼€å§‹æ‰§è¡Œâ€œå¤šæ ·æ€§ä¼˜å…ˆï¼Œæ•°é‡ä¿è¯â€æ–‡ä»¶ç­›é€‰ç­–ç•¥...")

    df_fault_pool = df[(df['sampling_rate'] == '12k') & (df['sensor'] == 'DE')].copy()
    df_n = df[df['fault_type'] == 'N'].copy()
    print(f"  - [æ­£å¸¸ N]: ç›®æ ‡é€‰å–4ä¸ªï¼Œå®é™…é€‰å– {len(df_n)} ä¸ªã€‚")

    selection_targets = {
        'IR': [('007', '1'), ('014', '2'), ('021', '3'), ('028', '0'), ('007', '0')],
        'B': [('007', '1'), ('014', '2'), ('021', '3'), ('028', '0'), ('007', '0')],
        'OR': [('007', '1'), ('014', '2'), ('021', '3'), ('007', '0'), ('014', '0')]
    }

    final_selected_dfs = [df_n]
    for f_type, targets in selection_targets.items():
        target_count = 12
        df_pool = df_fault_pool[df_fault_pool['fault_type'] == f_type]

        primary_selection_list = []
        for size, load in targets:
            match = df_pool[(df_pool['fault_size'] == size) & (df_pool['load'] == load)]
            if not match.empty:
                primary_selection_list.append(match.iloc[[0]])

        df_primary = pd.concat(primary_selection_list, ignore_index=True) if primary_selection_list else pd.DataFrame()

        current_count = len(df_primary)
        if current_count < target_count:
            print(f"  - [{f_type}]: å¤šæ ·æ€§åˆé€‰å¾—åˆ° {current_count} ä¸ªï¼Œéœ€è¦è¡¥å…… {target_count - current_count} ä¸ªã€‚")
            remaining_indices = df_pool.index[~df_pool.index.isin(df_primary.index)]
            df_remaining = df_pool.loc[remaining_indices]

            num_to_add = target_count - current_count
            df_supplement = df_remaining.head(num_to_add)
            df_final_fault = pd.concat([df_primary, df_supplement], ignore_index=True)
        else:
            df_final_fault = df_primary.head(target_count)

        final_selected_dfs.append(df_final_fault)
        print(f"  - [{f_type}]: æœ€ç»ˆé€‰å– {len(df_final_fault)} ä¸ªæ–‡ä»¶ã€‚")

    final_df = pd.concat(final_selected_dfs, ignore_index=True)
    print("\nâœ… ç­›é€‰ç­–ç•¥æ‰§è¡Œå®Œæ¯•ï¼")
    return final_df


# ==============================================================================
# 3. ä¸»ç¨‹åº (ä¿æŒä¸å˜)
# ==============================================================================
if __name__ == "__main__":
    SOURCE_ROOT_DIR = os.path.join('..', 'data', 'source')

    # 1. ã€è°ƒç”¨æœ€ç»ˆç‰ˆå‡½æ•°ã€‘åˆ›å»ºå…ƒæ•°æ®è¡¨
    df_all_files = build_metadata_from_walk(SOURCE_ROOT_DIR)

    if not df_all_files.empty:
        print(f"\nğŸ“Š æˆåŠŸè§£æ {len(df_all_files)} ä¸ªæ–‡ä»¶ã€‚")

        # 2. æ‰§è¡Œç­›é€‰
        df_selected = select_files_guaranteed_count(df_all_files)

        print("\nğŸ“Š æœ€ç»ˆé€‰å®šçš„æ–‡ä»¶æ¦‚è§ˆ (æŒ‰æ•…éšœç±»å‹ç»Ÿè®¡):")
        print(df_selected['fault_type'].value_counts())

        # 3. ä¿å­˜ç»“æœ
        output_dir = os.path.join('..', 'data', 'processed')
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, 'step1_selected_source_files.csv')
        df_selected.to_csv(output_path, index=False, encoding='utf-8-sig')

        print(f"\nğŸ’¾ ç­›é€‰ç»“æœå·²ä¿å­˜è‡³: {output_path}")
        print("\nğŸ‰ æ­¥éª¤ä¸€ï¼šæ•°æ®åˆ†æä¸ç­›é€‰å®Œæˆï¼")
    else:
        print("\næœªæ‰¾åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶ï¼Œç¨‹åºå·²ç»ˆæ­¢ã€‚")