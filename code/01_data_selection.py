import os
import re
import pandas as pd
import numpy as np


# ==============================================================================
# 1. é€’å½’æ‰«æä¸å…ƒæ•°æ®æ„å»º (å®Œå…¨é‡‡çº³ä½ éªŒè¯è¿‡çš„ä»£ç )
# ==============================================================================
def build_metadata_from_walk(source_root_dir: str):
    """
    ã€é‡‡çº³ç‰ˆã€‘ä½¿ç”¨os.walké€’å½’æ‰«ææ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼Œå¹¶ä»è·¯å¾„å’Œæ–‡ä»¶åä¸­æå–ä¿¡æ¯ã€‚
    """
    records = []
    total_files_found = 0
    unparsed_files = []

    print(f"ğŸ” å¼€å§‹é€’å½’æ‰«ææ ¹ç›®å½•: {os.path.abspath(source_root_dir)}")

    if not os.path.exists(source_root_dir):
        print(f"â€¼ï¸ é”™è¯¯ï¼šæŒ‡å®šçš„è·¯å¾„ä¸å­˜åœ¨ï¼è¯·æ£€æŸ¥è·¯å¾„: {os.path.abspath(source_root_dir)}")
        return pd.DataFrame()

    for root, dirs, files in os.walk(source_root_dir):
        mat_files_in_this_folder = [f for f in files if f.endswith('.mat')]
        total_files_found += len(mat_files_in_this_folder)

        for filename in mat_files_in_this_folder:
            file_path = os.path.join(root, filename)
            path_lower = file_path.lower().replace('\\', '/')

            sampling_rate = '48k' if '48khz' in path_lower else '12k'
            sensor = 'DE' if 'de_data' in path_lower or 'normal_data' in path_lower else \
                'FE' if 'fe_data' in path_lower else \
                    'BA' if 'ba_data' in path_lower else 'unknown'

            fault_type, fault_size, load = None, None, None
            if 'normal_data' in path_lower:
                fault_type, fault_size, load = 'N', '000', '0'
            else:
                match = re.match(r'([A-Z]+)(\d{3})(?:@\d+)?_(\d).*?\.mat', filename, re.IGNORECASE)
                if match:
                    ft, fs, ld = match.groups()
                    fault_type, fault_size, load = ft.upper(), fs, ld

            if fault_type:
                records.append({
                    'filename': filename, 'file_path': file_path,
                    'sampling_rate': sampling_rate, 'sensor': sensor,
                    'fault_type': fault_type, 'fault_size': fault_size, 'load': load
                })
            else:
                unparsed_files.append(file_path)

    print(f"âœ… æ‰«æå®Œæˆï¼Œæ€»å…±æ‰¾åˆ° {total_files_found} ä¸ª .mat æ–‡ä»¶ã€‚")
    if unparsed_files:
        print(f"âš ï¸  å…¶ä¸­æœ‰ {len(unparsed_files)} ä¸ªæ–‡ä»¶å› å‘½åä¸è§„èŒƒæ— æ³•è§£æã€‚")

    return pd.DataFrame(records)


# ==============================================================================
# 2. ã€æ ¸å¿ƒä¿®æ”¹ã€‘æœ€ç»ˆç‰ˆæ•°æ®ç­›é€‰ç­–ç•¥å‡½æ•°
# ==============================================================================
def apply_final_selection_strategy(df_all_files: pd.DataFrame):
    """
    æ‰§è¡Œæˆ‘ä»¬æœ€ç»ˆç¡®å®šçš„ç­›é€‰ç­–ç•¥ï¼š
    1. æ­£å¸¸æ ·æœ¬ï¼šå…¨éƒ¨é€‰å–ã€‚
    2. æ•…éšœæ ·æœ¬ï¼šåªä¿ç•™é©±åŠ¨ç«¯(DE)ã€è½½è·ä¸º1æˆ–2é©¬åŠ›çš„æ ·æœ¬ã€‚
    """
    print("\nğŸš€ å¼€å§‹æ‰§è¡Œæœ€ç»ˆç‰ˆæ–‡ä»¶ç­›é€‰ç­–ç•¥...")

    # ç­–ç•¥1ï¼šé€‰å–æ‰€æœ‰æ­£å¸¸(N)æ ·æœ¬
    df_normal = df_all_files[df_all_files['fault_type'] == 'N'].copy()
    print(f"  - [æ­£å¸¸æ ·æœ¬] å·²é€‰æ‹©å…¨éƒ¨ {len(df_normal)} ä¸ªæ­£å¸¸æ–‡ä»¶ã€‚")

    # ç­–ç•¥2ï¼šç­›é€‰æ•…éšœæ ·æœ¬
    # å…ˆé€‰å‡ºæ‰€æœ‰æ•…éšœæ–‡ä»¶
    df_faults_initial = df_all_files[df_all_files['fault_type'] != 'N'].copy()

    # ç­›é€‰æ¡ä»¶ a: ä¼ æ„Ÿå™¨ä½ç½®å¿…é¡»æ˜¯ 'DE'
    df_faults_de = df_faults_initial[df_faults_initial['sensor'] == 'DE']
    print(
        f"  - [æ•…éšœæ ·æœ¬-ä¼ æ„Ÿå™¨] ä» {len(df_faults_initial)} ä¸ªæ•…éšœæ–‡ä»¶ä¸­, ç­›é€‰å‡º {len(df_faults_de)} ä¸ªé©±åŠ¨ç«¯(DE)æ–‡ä»¶ã€‚")

    # ç­›é€‰æ¡ä»¶ b: è½½è·å¿…é¡»æ˜¯ '1' æˆ– '2'
    df_faults_final = df_faults_de[df_faults_de['load'].isin(['1', '2'])]
    print(f"  - [æ•…éšœæ ·æœ¬-è½½è·] è¿›ä¸€æ­¥ç­›é€‰å‡º {len(df_faults_final)} ä¸ªè½½è·ä¸º1æˆ–2é©¬åŠ›çš„æ–‡ä»¶ã€‚")

    # åˆå¹¶æœ€ç»ˆé€‰æ‹©çš„æ­£å¸¸æ ·æœ¬å’Œæ•…éšœæ ·æœ¬
    df_selected = pd.concat([df_normal, df_faults_final], ignore_index=True)

    print("\nâœ… æœ€ç»ˆç­›é€‰ç­–ç•¥æ‰§è¡Œå®Œæ¯•ï¼")
    return df_selected


# ==============================================================================
# 3. ä¸»ç¨‹åº
# ==============================================================================
if __name__ == "__main__":
    # å®šä¹‰æºæ•°æ®æ ¹ç›®å½•
    SOURCE_ROOT_DIR = os.path.join('..', 'data', 'source')

    # 1. ä½¿ç”¨ä½ éªŒè¯è¿‡çš„å‡½æ•°ï¼Œæ‰«æå¹¶è§£ææ‰€æœ‰æ–‡ä»¶
    df_all_files = build_metadata_from_walk(SOURCE_ROOT_DIR)

    if not df_all_files.empty:
        print(f"\nğŸ“Š æˆåŠŸè§£æ {len(df_all_files)} ä¸ªæ–‡ä»¶ã€‚")

        # 2. åº”ç”¨æˆ‘ä»¬æœ€ç»ˆç¡®å®šçš„ç­›é€‰ç­–ç•¥
        df_selected = apply_final_selection_strategy(df_all_files)

        print("\nğŸ“Š æœ€ç»ˆé€‰å®šçš„æ–‡ä»¶æ¦‚è§ˆ (æŒ‰æ•…éšœç±»å‹ç»Ÿè®¡):")
        print(df_selected['fault_type'].value_counts())

        print("\n(æŒ‰è½½è·ç»Ÿè®¡):")
        print(df_selected['load'].value_counts())

        # 3. ä¿å­˜ç»“æœ
        output_dir = os.path.join('..', 'data', 'processed')
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, 'step1_selected_source_files.csv')
        df_selected.to_csv(output_path, index=False, encoding='utf-8-sig')

        print(f"\nğŸ’¾ æœ€ç»ˆç­›é€‰ç»“æœå·²ä¿å­˜è‡³: {os.path.abspath(output_path)}")
        print("\nğŸ‰ ä»»åŠ¡ä¸€æ•°æ®ç­›é€‰å·¥ä½œå·²æŒ‰æœ€ç»ˆæ–¹æ¡ˆå®Œæˆï¼")
    else:
        print("\næœªæ‰¾åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶ï¼Œç¨‹åºå·²ç»ˆæ­¢ã€‚")