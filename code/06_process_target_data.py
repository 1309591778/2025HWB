import os
import numpy as np
import pandas as pd
import scipy.io
import pywt
from scipy.stats import kurtosis, skew, entropy
from scipy.signal import hilbert


# ==============================================================================
# 1. å·¥å…·å‡½æ•° (ä¸03è„šæœ¬å®Œå…¨ä¸€è‡´)
# ==============================================================================
def load_mat_file(file_path: str):
    """è¯»å– .mat æ–‡ä»¶"""
    try:
        return scipy.io.loadmat(file_path)
    except NotImplementedError:
        import h5py
        mat_data = {}
        with h5py.File(file_path, 'r') as f:
            for key in f.keys():
                mat_data[key] = np.array(f[key])
        return mat_data
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ {os.path.basename(file_path)} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None


def calculate_theoretical_frequencies(rpm):
    """æ ¹æ®è½¬é€Ÿè®¡ç®—ç†è®ºæ•…éšœé¢‘ç‡ï¼Œä½¿ç”¨æºåŸŸè½´æ‰¿å‚æ•°ä½œä¸ºè¿‘ä¼¼"""
    if rpm == 0:
        return {'BPFI': 0, 'BPFO': 0, 'BSF': 0}
    n_balls, d_ball, D_pitch = 9, 0.3126, 1.537
    fr = rpm / 60.0
    bpfi = (n_balls / 2) * fr * (1 + (d_ball / D_pitch))
    bpfo = (n_balls / 2) * fr * (1 - (d_ball / D_pitch))
    bsf = (D_pitch / (2 * d_ball)) * fr * (1 - (d_ball / D_pitch) ** 2)
    return {'BPFI': bpfi, 'BPFO': bpfo, 'BSF': bsf}


# ==============================================================================
# 2. å®‰å…¨è®¡ç®—å‡½æ•° (æ–°å¢)
# ==============================================================================
def safe_divide(a, b, default=0):
    """å®‰å…¨é™¤æ³•è¿ç®—"""
    try:
        return float(a / b) if abs(b) > 1e-8 else default
    except:
        return default


def safe_sqrt(x, default=0):
    """å®‰å…¨å¹³æ–¹æ ¹è¿ç®—"""
    try:
        return float(np.sqrt(abs(x))) if abs(x) > 1e-8 else default
    except:
        return default


# ==============================================================================
# 3. ç›®æ ‡åŸŸæ•°æ®å¤„ç†ä¸ç‰¹å¾æå–æ ¸å¿ƒå‡½æ•° (å¢å¼ºç‰ˆ)
# ==============================================================================
def process_target_data(target_dir, segment_len=4096, stride=512):
    """
    åŠ è½½ã€åˆ†æ®µå¹¶æå–æ‰€æœ‰ç›®æ ‡åŸŸæ–‡ä»¶çš„ç‰¹å¾ï¼Œç¡®ä¿ä¸æºåŸŸç‰¹å¾æå–é€»è¾‘å®Œå…¨ä¸€è‡´ã€‚
    """
    all_features_list = []

    # [cite_start]æ ¹æ®èµ›é¢˜æè¿°ï¼Œè®¾å®šç›®æ ‡åŸŸçš„å›ºå®šå‚æ•° [cite: 41]
    target_sr = 32000
    target_rpm = 600

    print("ğŸš€ å¼€å§‹å¤„ç†ç›®æ ‡åŸŸæ•°æ®...")
    n = segment_len
    freq_axis = np.fft.fftfreq(n, 1 / target_sr)[:n // 2]
    target_files = sorted([f for f in os.listdir(target_dir) if f.endswith('.mat')])

    for filename in target_files:
        file_path = os.path.join(target_dir, filename)
        mat_data = load_mat_file(file_path)
        if not mat_data:
            continue

        signal_key = max((k for k in mat_data if isinstance(mat_data[k], np.ndarray) and mat_data[k].ndim > 1),
                         key=lambda k: mat_data[k].shape[0], default=None)
        if not signal_key:
            print(f"  - è­¦å‘Šï¼šåœ¨æ–‡ä»¶ {filename} ä¸­æœªæ‰¾åˆ°å¯ç”¨çš„ä¿¡å·æ•°æ®ï¼Œå·²è·³è¿‡ã€‚")
            continue
        signal = mat_data[signal_key].flatten()

        num_segments = 0
        for i in range(0, len(signal) - segment_len + 1, stride):
            segment = signal[i: i + segment_len]
            num_segments += 1

            # --- ç‰¹å¾æå– (ä¸03è„šæœ¬çš„æœ€ç»ˆå¢å¼ºç‰ˆé€»è¾‘å®Œå…¨ä¸€è‡´) ---
            # 1. æ—¶åŸŸç‰¹å¾
            rms = np.sqrt(np.mean(segment ** 2))
            kurt = kurtosis(segment)
            sk = skew(segment)
            peak_to_peak = np.max(segment) - np.min(segment)
            crest_factor = np.max(np.abs(segment)) / rms if rms != 0 else 0
            std_dev = np.std(segment)
            clearance_factor = np.max(np.abs(segment)) / (np.mean(np.sqrt(np.abs(segment))) ** 2) if np.mean(
                np.sqrt(np.abs(segment))) != 0 else 0
            impulse_factor = np.max(np.abs(segment)) / np.mean(np.abs(segment)) if np.mean(np.abs(segment)) != 0 else 0

            # 2. é¢‘åŸŸç‰¹å¾ (åŸºäºåŒ…ç»œè°±ï¼Œå¹¶æ–°å¢è°æ³¢å¹…å€¼æ¯”)
            theo_freqs = calculate_theoretical_frequencies(target_rpm)
            envelope = np.abs(hilbert(segment))
            fft_vals_env = np.abs(np.fft.fft(envelope))[:n // 2]
            freq_features_env = {}
            harmonic_ratios = {}
            amplitudes = {}
            for f_type, f_val in theo_freqs.items():
                for j in range(1, 3):
                    target_freq = f_val * j
                    idx = np.argmin(np.abs(freq_axis - target_freq))
                    amp = fft_vals_env[idx]
                    amplitudes[f'{f_type}_{j}x'] = amp
                    freq_features_env[f'{f_type}_{j}x_env'] = amp
            for f_type in theo_freqs.keys():
                base_amp = amplitudes.get(f'{f_type}_1x', 0)
                harmonic_amp = amplitudes.get(f'{f_type}_2x', 0)
                harmonic_ratios[f'{f_type}_hr'] = harmonic_amp / base_amp if base_amp > 1e-6 else 0

            # 3. æ—¶é¢‘åŸŸç‰¹å¾ (æ–°å¢èƒ½é‡ç†µ)
            wp = pywt.WaveletPacket(data=segment, wavelet='db1', mode='symmetric', maxlevel=3)
            nodes = wp.get_level(3, order='natural')
            wavelet_energy = np.array([np.sum(node.data ** 2) for node in nodes])
            total_energy = np.sum(wavelet_energy)
            energy_dist = wavelet_energy / total_energy if total_energy > 1e-6 else np.zeros_like(wavelet_energy)
            wavelet_entropy = entropy(energy_dist, base=2)

            # ======================================================================
            # æ–°å¢ï¼šåŸºç¡€å¢å¼ºç‰¹å¾ (ä¸03è„šæœ¬ä¿æŒä¸€è‡´)
            # ======================================================================

            # 1. æ”¹è¿›çš„æ—¶åŸŸç‰¹å¾
            margin_factor = safe_divide(np.max(np.abs(segment)), np.mean(np.abs(segment)) ** 2)
            shape_factor = safe_divide(rms, np.mean(np.abs(segment)))

            # 2. æ”¹è¿›çš„é¢‘åŸŸç‰¹å¾
            spectral_features = {}
            if len(fft_vals_env) > 0:
                # é¢‘è°±é‡å¿ƒ
                spectral_centroid = safe_divide(np.sum(freq_axis * fft_vals_env), np.sum(fft_vals_env))
                # é¢‘è°±æ–¹å·®
                spectral_spread = safe_divide(np.sum(((freq_axis - spectral_centroid) ** 2) * fft_vals_env),
                                              np.sum(fft_vals_env))
                # é¢‘è°±ååº¦
                spectral_skewness = safe_divide(np.sum(((freq_axis - spectral_centroid) ** 3) * fft_vals_env),
                                                np.sum(fft_vals_env) * (safe_sqrt(spectral_spread) ** 3))
                # é¢‘è°±å³°åº¦
                spectral_kurtosis = safe_divide(np.sum(((freq_axis - spectral_centroid) ** 4) * fft_vals_env),
                                                np.sum(fft_vals_env) * (spectral_spread ** 2))

                spectral_features = {
                    'spectral_centroid': spectral_centroid,
                    'spectral_spread': spectral_spread,
                    'spectral_skewness': spectral_skewness,
                    'spectral_kurtosis': spectral_kurtosis
                }

            # 3. åŒ…ç»œåˆ†æç‰¹å¾
            envelope_features = {}
            if len(envelope) > 0:
                envelope_mean = np.mean(envelope)
                envelope_std = np.std(envelope)
                envelope_rms = np.sqrt(np.mean(envelope ** 2))

                envelope_features = {
                    'envelope_mean': envelope_mean,
                    'envelope_std': envelope_std,
                    'envelope_rms': envelope_rms,
                    'envelope_crest_factor': safe_divide(np.max(envelope), envelope_rms),
                    'envelope_impulse_factor': safe_divide(np.max(envelope), envelope_mean)
                }

            # ======================================================================
            # æ–°å¢ï¼šNç±»æ ·æœ¬å¢å¼ºç‰¹å¾ (ä¸03è„šæœ¬ä¿æŒä¸€è‡´)
            # ======================================================================
            n_class_specific_features = {}
            try:
                # å¹³ç¨³æ€§ç‰¹å¾ï¼šè‡ªç›¸å…³è¡°å‡ç‡
                autocorr = np.correlate(segment, segment, mode='full')
                autocorr = autocorr[len(autocorr) // 2:]
                # è®¡ç®—è‡ªç›¸å…³è¡°å‡ç‡ï¼ˆå‰100ä¸ªç‚¹ï¼‰
                decay_window = min(100, len(autocorr))
                if decay_window > 1:
                    decay_rate = np.sum(np.abs(np.diff(autocorr[:decay_window]))) / decay_window
                else:
                    decay_rate = 0

                # å™ªå£°æ°´å¹³ç‰¹å¾
                diff_seg = np.diff(segment)
                if len(diff_seg) > 0:
                    noise_level = safe_divide(np.std(diff_seg), np.std(segment))
                else:
                    noise_level = 0

                # å†²å‡»æŒ‡æ ‡ï¼ˆæ­£å¸¸ä¿¡å·åº”è¯¥å¾ˆå°‘æœ‰å†²å‡»ï¼‰
                envelope = np.abs(hilbert(segment))
                impulse_indicator = safe_divide(np.max(envelope), np.mean(envelope))

                n_class_specific_features = {
                    'N_autocorr_decay': float(decay_rate) if not np.isnan(decay_rate) else 0,
                    'N_noise_level': float(noise_level) if not np.isnan(noise_level) else 0,
                    'N_impulse_indicator': float(impulse_indicator) if not np.isnan(impulse_indicator) else 0
                }
            except:
                # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                n_class_specific_features = {
                    'N_autocorr_decay': 0,
                    'N_noise_level': 0,
                    'N_impulse_indicator': 0
                }

            # æ•´åˆæ‰€æœ‰ç‰¹å¾ (åŸæœ‰ä»£ç )
            features_full = {
                'source_file': filename, 'rpm': target_rpm,
                # åŸæœ‰ç‰¹å¾
                'rms': rms, 'kurtosis': kurt, 'skewness': sk,
                'peak_to_peak': peak_to_peak, 'crest_factor': crest_factor,
                'std_dev': std_dev, 'clearance_factor': clearance_factor,
                'impulse_factor': impulse_factor,
                'wavelet_entropy': wavelet_entropy,
                **freq_features_env,
                **harmonic_ratios,
                # æ–°å¢åŸºç¡€ç‰¹å¾
                'margin_factor': margin_factor,
                'shape_factor': shape_factor,
                **spectral_features,
                **envelope_features,
                # Nç±»ä¸“å±ç‰¹å¾ï¼ˆæ–°å¢ï¼‰
                **n_class_specific_features,
            }
            for j, energy in enumerate(wavelet_energy):
                features_full[f'wavelet_energy_{j}'] = energy

            # --- ã€æ–°å¢ã€‘åªä¿ç•™ä»»åŠ¡ä¸€é€‰å®šçš„ç‰¹å¾ ---
            # ç¡®ä¿ selected_feature_names åœ¨å‡½æ•°ä½œç”¨åŸŸå†…å¯ç”¨ï¼Œæˆ–è€…ä½œä¸ºå‚æ•°ä¼ å…¥
            # è¿™é‡Œå‡è®¾ selected_feature_names æ˜¯å…¨å±€åŠ è½½çš„ï¼Œæˆ–è€…é€šè¿‡å…¶ä»–æ–¹å¼ä¼ é€’
            # ä¸ºç®€åŒ–ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œç›´æ¥ç­›é€‰ï¼Œä½†æ›´å¥å£®çš„åšæ³•æ˜¯åœ¨å‡½æ•°å‚æ•°ä¸­ä¼ é€’ selected_feature_names
            # æˆ–è€…åœ¨å‡½æ•°å†…éƒ¨é‡æ–°åŠ è½½ï¼ˆä¸æ¨èï¼Œæ•ˆç‡ä½ï¼‰
            # ä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼šå‡è®¾ selected_feature_names å·²åœ¨ä¸»ç¨‹åºå¼€å§‹æ—¶åŠ è½½ä¸ºå…¨å±€å˜é‡
            global selected_feature_names  # å£°æ˜ä½¿ç”¨å…¨å±€å˜é‡
            features_selected = {'source_file': filename, 'rpm': target_rpm}  # ä¿ç•™å¿…è¦ä¿¡æ¯
            for fname in selected_feature_names:
                if fname in features_full:
                    features_selected[fname] = features_full[fname]
                else:
                    print(f"  - è­¦å‘Šï¼šåœ¨ç›®æ ‡åŸŸç‰¹å¾ä¸­æœªæ‰¾åˆ°ä»»åŠ¡ä¸€é€‰å®šçš„ç‰¹å¾ '{fname}'ï¼Œå°†å¡«å……ä¸º0ã€‚")
                    features_selected[fname] = 0  # æˆ–è€… np.nan, æ ¹æ®æ¨¡å‹å®¹å¿åº¦å†³å®š
            # --- ã€æ–°å¢ç»“æŸã€‘ ---

            # all_features_list.append(features) # æ³¨é‡Šæ‰æ—§çš„æ·»åŠ æ–¹å¼
            all_features_list.append(features_selected)  # æ·»åŠ ç­›é€‰åçš„ç‰¹å¾

        print(f"  - âœ… å·²å¤„ç†: {filename} -> ç”Ÿæˆäº† {num_segments} ä¸ªæ ·æœ¬æ®µã€‚")

    print("\nâœ… ç›®æ ‡åŸŸæ•°æ®ç‰¹å¾æå–å®Œæˆï¼")
    return pd.DataFrame(all_features_list)


# ==============================================================================
# 3. ä¸»ç¨‹åº
# ==============================================================================
if __name__ == "__main__":
    TARGET_DATA_DIR = os.path.join('..', 'data', 'target')
    PROCESSED_DIR = os.path.join('..', 'data', 'processed')
    TARGET_FEATURES_PATH = os.path.join(PROCESSED_DIR, 'target_features.csv')

    # --- ã€æ–°å¢ã€‘åŠ è½½ä»»åŠ¡ä¸€ç­›é€‰å‡ºçš„ç‰¹å¾åç§° ---
    SELECTED_FEATURES_PATH = os.path.join('..', 'data', 'processed', 'selected_feature_names.txt')
    try:
        with open(SELECTED_FEATURES_PATH, 'r') as f:
            # è¯»å–ç‰¹å¾åå¹¶å»é™¤æ¢è¡Œç¬¦
            selected_feature_names = [line.strip() for line in f.readlines()]
        print(f"âœ… æˆåŠŸåŠ è½½ä»»åŠ¡ä¸€ç­›é€‰å‡ºçš„ç‰¹å¾åˆ—è¡¨ï¼Œå…± {len(selected_feature_names)} ä¸ªç‰¹å¾ã€‚")
        # print(f"ç‰¹å¾åˆ—è¡¨: {selected_feature_names}") # å¯é€‰ï¼šæ‰“å°ç¡®è®¤
    except FileNotFoundError:
        print(f"â€¼ï¸ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ä»»åŠ¡ä¸€çš„ç‰¹å¾åˆ—è¡¨æ–‡ä»¶ {SELECTED_FEATURES_PATH}ã€‚è¯·å…ˆè¿è¡Œä»»åŠ¡ä¸€çš„ç‰¹å¾ç­›é€‰è„šæœ¬ã€‚")
        exit(1)
    except Exception as e:
        print(f"â€¼ï¸ åŠ è½½ç‰¹å¾åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        exit(1)
    # --- ã€æ–°å¢ç»“æŸã€‘ ---

    df_target_features = process_target_data(TARGET_DATA_DIR)

    if not df_target_features.empty:
        print("\nğŸ“Š ç›®æ ‡åŸŸç‰¹å¾é›†é¢„è§ˆ (å‰5è¡Œ):")
        print(df_target_features.head())
        print(f"\nç‰¹å¾é›†ç»´åº¦: {df_target_features.shape}")
        df_target_features.to_csv(TARGET_FEATURES_PATH, index=False)
        print(f"\nğŸ’¾ ç›®æ ‡åŸŸå…¨ç‰¹å¾é›†å·²ä¿å­˜è‡³: {TARGET_FEATURES_PATH}")
    else:
        print("\næœªèƒ½åœ¨ç›®æ ‡ç›®å½•ä¸­å¤„ç†ä»»ä½•æ–‡ä»¶ã€‚")