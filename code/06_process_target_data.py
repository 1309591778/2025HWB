# 06_target_features.py
import os
import numpy as np
import pandas as pd
import scipy.io
import pywt
from scipy.stats import kurtosis, skew, entropy
from scipy.signal import hilbert


# ==============================================================================
# 1. å·¥å…·å‡½æ•° (ä¸03è„šæœ¬å®Œå…¨ä¸€è‡´)
# ==============================================================================
def load_mat_file(file_path: str):
    """è¯»å– .mat æ–‡ä»¶"""
    try:
        return scipy.io.loadmat(file_path)
    except NotImplementedError:
        import h5py
        mat_data = {}
        with h5py.File(file_path, 'r') as f:
            for key in f.keys():
                mat_data[key] = np.array(f[key])
        return mat_data
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ {os.path.basename(file_path)} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None


# === MODIFIED ===
def calculate_normalized_frequencies():
    """
    è¿”å›SKF6205è½´æ‰¿çš„å½’ä¸€åŒ–æ•…éšœç‰¹å¾é¢‘ç‡ï¼ˆç›¸å¯¹äºè½¬é¢‘ fr çš„å€æ•°ï¼Œæ— é‡çº²ï¼‰
    """
    n_balls = 9
    d_ball = 0.3126
    D_pitch = 1.537
    bpfi_norm = (n_balls / 2) * (1 + (d_ball / D_pitch))
    bpfo_norm = (n_balls / 2) * (1 - (d_ball / D_pitch))
    bsf_norm = (D_pitch / (2 * d_ball)) * (1 - (d_ball / D_pitch) ** 2)
    return {'BPFI_norm': bpfi_norm, 'BPFO_norm': bpfo_norm, 'BSF_norm': bsf_norm}


# === MODIFIED END ===

# ==============================================================================
# 2. å®‰å…¨è®¡ç®—å‡½æ•° (æ–°å¢)
# ==============================================================================
def safe_divide(a, b, default=0):
    """å®‰å…¨é™¤æ³•è¿ç®—"""
    try:
        return float(a / b) if abs(b) > 1e-8 else default
    except:
        return default


def safe_sqrt(x, default=0):
    """å®‰å…¨å¹³æ–¹æ ¹è¿ç®—"""
    try:
        return float(np.sqrt(abs(x))) if abs(x) > 1e-8 else default
    except:
        return default


# ==============================================================================
# 3. ç›®æ ‡åŸŸæ•°æ®å¤„ç†ä¸ç‰¹å¾æå–æ ¸å¿ƒå‡½æ•° (MODIFIED: ä½¿ç”¨å½’ä¸€åŒ–é¢‘ç‡)
# ==============================================================================
def process_target_data(target_dir, segment_len=3200, stride=400):
    """
    åŠ è½½ã€åˆ†æ®µå¹¶æå–æ‰€æœ‰ç›®æ ‡åŸŸæ–‡ä»¶çš„ç‰¹å¾ï¼Œç¡®ä¿ä¸æºåŸŸç‰¹å¾æå–é€»è¾‘å®Œå…¨ä¸€è‡´ã€‚
    """
    all_features_list = []
    # [cite_start]æ ¹æ®èµ›é¢˜æè¿°ï¼Œè®¾å®šç›®æ ‡åŸŸçš„å›ºå®šå‚æ•° [cite: 41]
    target_sr = 32000
    target_rpm = 600  # å›ºå®šè½¬é€Ÿ
    print("ğŸš€ å¼€å§‹å¤„ç†ç›®æ ‡åŸŸæ•°æ®...")
    n = segment_len
    freq_axis = np.fft.fftfreq(n, 1 / target_sr)[:n // 2]

    # === MODIFIED ===
    # é¢„å…ˆè®¡ç®—å½’ä¸€åŒ–é¢‘ç‡ï¼ˆæ— é‡çº²ï¼Œä¸RPMæ— å…³ï¼‰
    norm_freqs = calculate_normalized_frequencies()
    # è®¡ç®—è½¬é¢‘ (Hz)
    fr = target_rpm / 60.0  # = 10 Hz
    # === MODIFIED END ===

    target_files = sorted([f for f in os.listdir(target_dir) if f.endswith('.mat')])
    for filename in target_files:
        file_path = os.path.join(target_dir, filename)
        mat_data = load_mat_file(file_path)
        if not mat_data:
            continue
        signal_key = max((k for k in mat_data if isinstance(mat_data[k], np.ndarray) and mat_data[k].ndim > 1),
                         key=lambda k: mat_data[k].shape[0], default=None)
        if not signal_key:
            print(f"  - è­¦å‘Šï¼šåœ¨æ–‡ä»¶ {filename} ä¸­æœªæ‰¾åˆ°å¯ç”¨çš„ä¿¡å·æ•°æ®ï¼Œå·²è·³è¿‡ã€‚")
            continue
        signal = mat_data[signal_key].flatten()
        # --- æ–°å¢ï¼šæ¸…ç†æ— æ•ˆå€¼ (ä¸æºåŸŸå¤„ç†æ–¹å¼ä¸€è‡´) ---
        signal = signal[np.isfinite(signal)]
        if len(signal) < segment_len:
            print(f"  - è­¦å‘Šï¼šæ–‡ä»¶ {filename} æ¸…ç†åé•¿åº¦ä¸è¶³ {segment_len}ï¼Œå·²è·³è¿‡ã€‚")
            continue
        # --- æ–°å¢ç»“æŸ ---
        num_segments = 0
        for i in range(0, len(signal) - segment_len + 1, stride):
            segment = signal[i: i + segment_len]
            num_segments += 1
            # --- ç‰¹å¾æå– (ä¸03è„šæœ¬çš„æœ€ç»ˆå¢å¼ºç‰ˆé€»è¾‘å®Œå…¨ä¸€è‡´) ---
            # 1. æ—¶åŸŸç‰¹å¾
            rms = np.sqrt(np.mean(segment ** 2))
            kurt = kurtosis(segment)
            sk = skew(segment)
            peak_to_peak = np.max(segment) - np.min(segment)
            crest_factor = np.max(np.abs(segment)) / rms if rms != 0 else 0
            std_dev = np.std(segment)
            clearance_factor = np.max(np.abs(segment)) / (np.mean(np.sqrt(np.abs(segment))) ** 2) if np.mean(
                np.sqrt(np.abs(segment))) != 0 else 0
            impulse_factor = np.max(np.abs(segment)) / np.mean(np.abs(segment)) if np.mean(np.abs(segment)) != 0 else 0

            # 2. é¢‘åŸŸç‰¹å¾ (åŸºäºåŒ…ç»œè°±ï¼Œå¹¶æ–°å¢è°æ³¢å¹…å€¼æ¯”)
            envelope = np.abs(hilbert(segment))
            fft_vals_env = np.abs(np.fft.fft(envelope))[:n // 2]
            freq_features_env = {}
            harmonic_ratios = {}
            amplitudes = {}

            # === MODIFIED ===
            # ä½¿ç”¨å½’ä¸€åŒ–é¢‘ç‡ * è½¬é¢‘ = ç»å¯¹é¢‘ç‡
            for f_type_norm, f_norm in norm_freqs.items():
                f_type = f_type_norm.replace('_norm', '')  # 'BPFI_norm' -> 'BPFI'
                for j in range(1, 3):
                    target_freq = (f_norm * j) * fr  # å½’ä¸€åŒ–é¢‘ç‡ * è½¬é¢‘ = ç»å¯¹é¢‘ç‡
                    idx = np.argmin(np.abs(freq_axis - target_freq))
                    amp = fft_vals_env[idx]
                    amplitudes[f'{f_type}_{j}x'] = amp
                    freq_features_env[f'{f_type}_{j}x_env'] = amp
            # === MODIFIED END ===

            for f_type in ['BPFI', 'BPFO', 'BSF']:
                base_amp = amplitudes.get(f'{f_type}_1x', 0)
                harmonic_amp = amplitudes.get(f'{f_type}_2x', 0)
                harmonic_ratios[f'{f_type}_hr'] = harmonic_amp / base_amp if base_amp > 1e-6 else 0

            # 3. æ—¶é¢‘åŸŸç‰¹å¾ (æ–°å¢èƒ½é‡ç†µ)
            wp = pywt.WaveletPacket(data=segment, wavelet='db1', mode='symmetric', maxlevel=3)
            nodes = wp.get_level(3, order='natural')
            wavelet_energy = np.array([np.sum(node.data ** 2) for node in nodes])
            total_energy = np.sum(wavelet_energy)
            energy_dist = wavelet_energy / total_energy if total_energy > 1e-6 else np.zeros_like(wavelet_energy)
            wavelet_entropy = entropy(energy_dist, base=2)

            # ======================================================================
            # æ–°å¢ï¼šåŸºç¡€å¢å¼ºç‰¹å¾ (ä¸03è„šæœ¬ä¿æŒä¸€è‡´)
            # ======================================================================
            # 1. æ”¹è¿›çš„æ—¶åŸŸç‰¹å¾
            margin_factor = safe_divide(np.max(np.abs(segment)), np.mean(np.abs(segment)) ** 2)
            shape_factor = safe_divide(rms, np.mean(np.abs(segment)))
            # 2. æ”¹è¿›çš„é¢‘åŸŸç‰¹å¾
            spectral_features = {}
            if len(fft_vals_env) > 0:
                # é¢‘è°±é‡å¿ƒ
                spectral_centroid = safe_divide(np.sum(freq_axis * fft_vals_env), np.sum(fft_vals_env))
                # é¢‘è°±æ–¹å·®
                spectral_spread = safe_divide(np.sum(((freq_axis - spectral_centroid) ** 2) * fft_vals_env),
                                              np.sum(fft_vals_env))
                # é¢‘è°±ååº¦
                spectral_skewness = safe_divide(np.sum(((freq_axis - spectral_centroid) ** 3) * fft_vals_env),
                                                np.sum(fft_vals_env) * (safe_sqrt(spectral_spread) ** 3))
                # é¢‘è°±å³°åº¦
                spectral_kurtosis = safe_divide(np.sum(((freq_axis - spectral_centroid) ** 4) * fft_vals_env),
                                                np.sum(fft_vals_env) * (spectral_spread ** 2))
                spectral_features = {
                    'spectral_centroid': spectral_centroid,
                    'spectral_spread': spectral_spread,
                    'spectral_skewness': spectral_skewness,
                    'spectral_kurtosis': spectral_kurtosis
                }
            # 3. åŒ…ç»œåˆ†æç‰¹å¾
            envelope_features = {}
            if len(envelope) > 0:
                envelope_mean = np.mean(envelope)
                envelope_std = np.std(envelope)
                envelope_rms = np.sqrt(np.mean(envelope ** 2))
                envelope_features = {
                    'envelope_mean': envelope_mean,
                    'envelope_std': envelope_std,
                    'envelope_rms': envelope_rms,
                    'envelope_crest_factor': safe_divide(np.max(envelope), envelope_rms),
                    'envelope_impulse_factor': safe_divide(np.max(envelope), envelope_mean)
                }

            # ======================================================================
            # æ–°å¢ï¼šNç±»æ ·æœ¬å¢å¼ºç‰¹å¾ (ä¸03è„šæœ¬ä¿æŒä¸€è‡´)
            # ======================================================================
            n_class_specific_features = {}
            try:
                # å¹³ç¨³æ€§ç‰¹å¾ï¼šè‡ªç›¸å…³è¡°å‡ç‡
                autocorr = np.correlate(segment, segment, mode='full')
                autocorr = autocorr[len(autocorr) // 2:]
                # è®¡ç®—è‡ªç›¸å…³è¡°å‡ç‡ï¼ˆå‰100ä¸ªç‚¹ï¼‰
                decay_window = min(100, len(autocorr))
                if decay_window > 1:
                    decay_rate = np.sum(np.abs(np.diff(autocorr[:decay_window]))) / decay_window
                else:
                    decay_rate = 0
                # å™ªå£°æ°´å¹³ç‰¹å¾
                diff_seg = np.diff(segment)
                if len(diff_seg) > 0:
                    noise_level = safe_divide(np.std(diff_seg), np.std(segment))
                else:
                    noise_level = 0
                # å†²å‡»æŒ‡æ ‡ï¼ˆæ­£å¸¸ä¿¡å·åº”è¯¥å¾ˆå°‘æœ‰å†²å‡»ï¼‰
                envelope = np.abs(hilbert(segment))
                impulse_indicator = safe_divide(np.max(envelope), np.mean(envelope))
                n_class_specific_features = {
                    'N_autocorr_decay': float(decay_rate) if not np.isnan(decay_rate) else 0,
                    'N_noise_level': float(noise_level) if not np.isnan(noise_level) else 0,
                    'N_impulse_indicator': float(impulse_indicator) if not np.isnan(impulse_indicator) else 0
                }
            except:
                # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                n_class_specific_features = {
                    'N_autocorr_decay': 0,
                    'N_noise_level': 0,
                    'N_impulse_indicator': 0
                }

            # æ•´åˆæ‰€æœ‰ç‰¹å¾ (åŸæœ‰ä»£ç )
            features_full = {
                'source_file': filename, 'rpm': target_rpm,
                # åŸæœ‰ç‰¹å¾
                'rms': rms, 'kurtosis': kurt, 'skewness': sk,
                'peak_to_peak': peak_to_peak, 'crest_factor': crest_factor,
                'std_dev': std_dev, 'clearance_factor': clearance_factor,
                'impulse_factor': impulse_factor,
                'wavelet_entropy': wavelet_entropy,
                **freq_features_env,
                **harmonic_ratios,
                # æ–°å¢åŸºç¡€ç‰¹å¾
                'margin_factor': margin_factor,
                'shape_factor': shape_factor,
                **spectral_features,
                **envelope_features,
                # Nç±»ä¸“å±ç‰¹å¾ï¼ˆæ–°å¢ï¼‰
                **n_class_specific_features,
            }
            for j, energy in enumerate(wavelet_energy):
                features_full[f'wavelet_energy_{j}'] = energy

            # --- ã€æ–°å¢ã€‘åªä¿ç•™ä»»åŠ¡ä¸€é€‰å®šçš„ç‰¹å¾ ---
            global selected_feature_names  # å£°æ˜ä½¿ç”¨å…¨å±€å˜é‡
            features_selected = {'source_file': filename, 'rpm': target_rpm}  # ä¿ç•™å¿…è¦ä¿¡æ¯
            for fname in selected_feature_names:
                if fname in features_full:
                    features_selected[fname] = features_full[fname]
                else:
                    print(f"  - è­¦å‘Šï¼šåœ¨ç›®æ ‡åŸŸç‰¹å¾ä¸­æœªæ‰¾åˆ°ä»»åŠ¡ä¸€é€‰å®šçš„ç‰¹å¾ '{fname}'ï¼Œå°†å¡«å……ä¸º0ã€‚")
                    features_selected[fname] = 0
            # --- ã€æ–°å¢ç»“æŸã€‘ ---
            all_features_list.append(features_selected)
        print(f"  - âœ… å·²å¤„ç†: {filename} -> ç”Ÿæˆäº† {num_segments} ä¸ªæ ·æœ¬æ®µã€‚")
    print("\nâœ… ç›®æ ‡åŸŸæ•°æ®ç‰¹å¾æå–å®Œæˆï¼")
    return pd.DataFrame(all_features_list)


# ==============================================================================
# 3. ä¸»ç¨‹åº
# ==============================================================================
if __name__ == "__main__":
    TARGET_DATA_DIR = os.path.join('..', 'data', 'target')
    PROCESSED_DIR = os.path.join('..', 'data', 'processed')
    TARGET_FEATURES_PATH = os.path.join(PROCESSED_DIR, 'target_features.csv')
    # --- ã€æ–°å¢ã€‘åŠ è½½ä»»åŠ¡ä¸€ç­›é€‰å‡ºçš„ç‰¹å¾åç§° ---
    SELECTED_FEATURES_PATH = os.path.join('..', 'data', 'processed', 'selected_feature_names.txt')
    try:
        with open(SELECTED_FEATURES_PATH, 'r') as f:
            selected_feature_names = [line.strip() for line in f.readlines()]
        print(f"âœ… æˆåŠŸåŠ è½½ä»»åŠ¡ä¸€ç­›é€‰å‡ºçš„ç‰¹å¾åˆ—è¡¨ï¼Œå…± {len(selected_feature_names)} ä¸ªç‰¹å¾ã€‚")
    except FileNotFoundError:
        print(f"â€¼ï¸ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ä»»åŠ¡ä¸€çš„ç‰¹å¾åˆ—è¡¨æ–‡ä»¶ {SELECTED_FEATURES_PATH}ã€‚è¯·å…ˆè¿è¡Œä»»åŠ¡ä¸€çš„ç‰¹å¾ç­›é€‰è„šæœ¬ã€‚")
        exit(1)
    except Exception as e:
        print(f"â€¼ï¸ åŠ è½½ç‰¹å¾åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        exit(1)
    # --- ã€æ–°å¢ç»“æŸã€‘ ---
    df_target_features = process_target_data(TARGET_DATA_DIR)
    if not df_target_features.empty:
        print("\nğŸ“Š ç›®æ ‡åŸŸç‰¹å¾é›†é¢„è§ˆ (å‰5è¡Œ):")
        print(df_target_features.head())
        print(f"\nç‰¹å¾é›†ç»´åº¦: {df_target_features.shape}")
        # --- æ–°å¢ï¼šå¤„ç†ç›®æ ‡åŸŸç‰¹å¾é›†ä¸­çš„ç¼ºå¤±å€¼å’Œæ— ç©·å€¼ (ä¸æºåŸŸå¤„ç†æ–¹å¼ä¸€è‡´) ---
        print("ğŸ” å¼€å§‹å¤„ç†ç›®æ ‡åŸŸç‰¹å¾é›†ä¸­çš„å¼‚å¸¸å€¼...")
        nan_count_before = df_target_features.isnull().sum().sum()
        inf_count_before = np.isinf(df_target_features.select_dtypes(include=[np.number])).sum().sum()
        print(f"  - å¤„ç†å‰ - NaNå€¼: {nan_count_before}, æ— ç©·å€¼: {inf_count_before}")
        df_target_features = df_target_features.replace([np.inf, -np.inf], np.nan)
        numeric_columns = df_target_features.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            if df_target_features[col].isnull().any():
                mean_value = df_target_features[col].mean()
                df_target_features[col].fillna(mean_value, inplace=True)
        nan_count_after = df_target_features.isnull().sum().sum()
        inf_count_after = np.isinf(df_target_features.select_dtypes(include=[np.number])).sum().sum()
        print(f"  - å¤„ç†å - NaNå€¼: {nan_count_after}, æ— ç©·å€¼: {inf_count_after}")
        # --- æ–°å¢ç»“æŸ ---
        df_target_features.to_csv(TARGET_FEATURES_PATH, index=False)
        print(f"\nğŸ’¾ ç›®æ ‡åŸŸå…¨ç‰¹å¾é›†å·²ä¿å­˜è‡³: {TARGET_FEATURES_PATH}")
    else:
        print("\næœªèƒ½åœ¨ç›®æ ‡ç›®å½•ä¸­å¤„ç†ä»»ä½•æ–‡ä»¶ã€‚")